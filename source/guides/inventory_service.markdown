---
layout: default
title: Inventory Service
---

Inventory Service
======

Set up and begin using the inventory service with one or more puppet master servers. **This document refers to a feature currently under development.**

* * *

[authdotconf]: ./rest_auth_conf.html
[rest]: ./rest_api.html#facts
[storeconfigs]: http://projects.puppetlabs.com/projects/1/wiki/Using_Stored_Configuration

Puppet 2.6.7 (unreleased at the time of this writing) adds support for maintaining, reading, and searching an inventory of nodes. This can be used to generate reports about the composition of your site, to drastically extend the capabilities of your external node classifier, and probably to do a lot of things we haven't even thought of yet. This service is designed as a _hackable public API._

What It Is
-----

The inventory itself consists of a collection of node facts, maintained in either a directory of YAML files or a database table. The inventory _service_ consists of the inventory APIs exposed by the puppet master. Other tools, including Puppet Dashboard, can access the inventory via the puppet master's REST API.

* When agent nodes report their facts to the master in the process of requesting a catalog, the master will record those facts to the inventory. If the node has never been inventoried before, a record will be created; if a record for the node already exists, it will be overwritten with the new information. The inventory does not record historical information for a given node; it only represents the puppet master's most current knowledge about said node. The inventory also doesn't automatically expire information for any node; if this is desired, it must be manually arranged for.
* Optionally, other puppet masters (or other processes entirely) can be configured to send facts submitted by THEIR agents to the inventory. This is accomplished using the RESTful network API exposed by the inventorying master (using the `facts` resource). The inventorying master's auth.conf file is read to determine which hosts are allowed to submit facts via the API.
* Other tools can request the facts for an arbitrary node using the REST API exposed by the inventorying master (using the `facts` resource). Access is controlled by auth.conf.
* Other tools can request a list of nodes which meet certain conditions, generated by searching fact values. This is done via the REST API exposed by the inventorying master (using the `facts_search` resource). Access is controlled by auth.conf.

The inventory search capability is especially powerful, as it can allow your provisioning system or ENC to make decisions about new hardware based on how many nodes fulfilling a given role currently exist.

Why
---

Users have previously built custom inventory functionality by directly reading either the puppet master's local YAML cache or the optional [storeconfigs][] database. Both of these approaches are non-optimal:

* The YAML cache is strictly local to a single puppet master, and can't provide an accurate inventory in multi-master environments. Furthermore, repeatedly deserializing YAML is slow slow slow, which can cause real problems depending on the use case. (Searching by fact, in particular, is basically not an option.)
* Storeconfigs, on the other hand, is global to the site, but it's essentially a private API: The only way to get information out of it is to read the database directly, and since the only officially supported use of it is for sharing exported resources, there's been no guarantee against the schema changing. More to the point, it's too heavyweight for users who just want an inventory: it stores every resource and tag in each node's catalog in addition to the node's facts, and even the "thin" storeconfigs option stores a LOT of data. Implementing storeconfigs at a reasonable scale demands setting up a message queue, and even that extra infrastructure doesn't necessarily make it viable at a large scale.

Thus, the Puppet inventory service: a relatively speedy implementation that does one thing well and exposes a public network API.

Consumers of the Inventory Service
-------

Inventory data is not currently read by any part of Puppet. The only application which reads the inventory service API as of this writing is a yet-to-be-released version of Puppet Dashboard, which shows the current facts in node views and provides a web interface for searching the inventory by fact.

Setting Up the Inventory Service
-----

### Configuring the Inventory Backend

The inventory service's backend is configured with the `facts_terminus` setting in the puppet master's section of `puppet.conf`.

#### For Prototyping: YAML

    [master]
        facts_terminus = yaml

You can actually start using the inventory service with the YAML backend immediately --- `yaml` is the default value for `facts_terminus`, and the YAML cache of any previously used puppet master will already be populated with fact information. Just configure access and you're good to go.

#### For Production: Database

    [master]
        facts_terminus = inventory_active_record
        dbadapter = {sqlite3|mysql|postgresql|oracle_enhanced}
        dbname = {database name (all but sqlite)}
        dbuser = {database user (all but sqlite)}
        dbpassword = {database password (all but sqlite)}
        dbserver = {database server (MySQL and PostgreSQL only)}
        dbsocket = {database socket file (MySQL only; optional)}
        dblocation = {sqlite file path (sqlite only)}

First, you or your DBA will need to create a database for Puppet and a user with all privileges on that database; the details of this are outside the scope of this document, and may include installing a database server on the puppet master.

Next, you will need to ensure that the puppet master server has the necessary software for communicating with the database. On all operating systems, this will entail ensuring that Rails is installed. In addition, you may need:

* The `libsqlite3-ruby` or `libmysql-ruby` packages (on Debian and Ubuntu)
* The `sqlite3-ruby`, `mysql`, or `postgres` gems
* And possibly more.

The necessary database configuration and software is identical to that used by storeconfigs, so [the Puppet wiki page for storeconfigs][storeconfigs] can be helpful. Getting MySQL on the local host configured is very well-documented; other options, less so.

#### For Additional Puppet Masters: REST

    [master]
        facts_terminus = rest
        inventory_server = {hostname of inventorying master; defaults to "puppet"}
        inventory_port = 8140 (unless changed)

In addition to writing to its local YAML cache, any puppet master with a facts_terminus of `rest` will submit facts to another puppet master.

### Configuring Access In auth.conf

Configuring the backend will ensure that puppet master maintains an inventory, but it won't expose it to external applications yet; for that, you'll have to edit the [`rest_authconfig` (`auth.conf`)][authdotconf] file.

For prototyping your API-consuming application, you can simply create an auth.conf file with every [default ACL](./rest_auth_conf.html#default-acls) and modify the final ACL that matches `/` --- either add an `allow *` line, or (more sanely) an `allow {hostname}` line that restricts super-access to one or more development machines. (Creating a complete auth.conf with redundant copies of every default ACL is necessary because of the linear way ACLs are matched --- if you create a stub auth.conf that only includes the ACL matching `/` with `auth any`, it will match every request before any of the default ACLs are given a chance. This won't present any symptoms if you chose to `allow *`, but can cause headaches later.)

For production deployment, you'll need to come up with ACLs that allow access to your application, allow any other puppet masters at your site to submit their nodes' facts, and deny access to any rogue agent nodes. (Since agent nodes submit their facts as part of their request to the `catalog` resource, they don't require access to the `facts` or `facts_search` resources.) One possible ACL set would be:

    path /facts
    auth yes
    method find, search
    allow custominventorybrowser.site.org

    path /facts
    auth yes
    method save
    allow puppetmaster*.site.org

The `auth yes` requirement means you would have to generate, sign, and distribute an SSL certificate to your app server; this could be accomplished by generating one locally and using the certificate signing request REST API, or by generating a cert on the puppet master with `puppet cert --generate custominventorybrowser.site.org` and moving the .pem files manually.

Testing the Inventory Service
-------

On a machine that you've authorized to access the facts and facts_search resources, you can test the API using `curl`, as described in the [REST API docs][rest]. To retrieve facts for a node:

    curl -k -H "Accept: yaml" https://puppet:8140/production/facts/{node certname}

To insert facts for a fictional node into the inventory:

    curl -k -X PUT -H 'Content-Type: text/yaml' --data-binary @/var/lib/puppet/yaml/facts/hostname.yaml https://puppet:8140/production/facts/{node certname}

To find out which nodes at your site have two or more processors and are running Ubuntu Linux:

    curl -k -H "Accept: pson" https://puppet:8140/production/facts_search/search?facts.processorcount.ge=2&facts.operatingsystem=Ubuntu

For complete documentation of the inventory API, see [the relevant section of the REST API docs][rest].

